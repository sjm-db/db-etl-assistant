{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05865089-641d-4ec5-8beb-3ec9f0077ac8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#ETL Assist agent\n",
    "\n",
    "This notebook demonstrates how to build an Data EngineeringAgent Index that uses on behalf of user authentication. In this notebook you:\n",
    "1. Author an agent using the on behalf of user clients\n",
    "2. Log the Agent with API Scopes\n",
    "3. Deploy the Agent to Model Serving\n",
    "\n",
    " **_NOTE:_**  This notebook uses LangChain, but AI Agent Framework is compatible with any agent authoring framework, including LlamaIndex or pure Python agents written with the OpenAI SDK.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Build the UC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41ab4ce5-22d0-4803-8330-175e3117b0a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyter-server 1.23.4 requires anyio<4,>=3.1.0, but you have anyio 4.10.0 which is incompatible.\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -qqqq mlflow-skinny[databricks] langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79ff9f8a-cee4-4be6-803d-96b5010c1eb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define the agent in code\n",
    "Below we define our agent code in a single cell, enabling us to easily write it to a local Python file for subsequent logging and deployment using the `%%writefile` magic command.\n",
    "\n",
    "For more examples of tools to add to your agent, see [docs](https://docs.databricks.com/generative-ai/agent-framework/agent-tool.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86c16cc1-3369-4179-8bb4-baa1de89ac8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile agent.py\n",
    "from typing import Any, Generator, Optional, Sequence, Union\n",
    "import functools\n",
    "import os\n",
    "from typing import Any, Generator, Literal, Optional\n",
    "\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import ChatDatabricks, VectorSearchRetrieverTool\n",
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.credentials_provider import ModelServingUserCredentials\n",
    "from databricks_langchain.genie import GenieAgent\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from pydantic import BaseModel\n",
    "\n",
    "###################################################\n",
    "## Create a GenieAgent with access to a Genie Space\n",
    "###################################################\n",
    "\n",
    "# TODO add GENIE_SPACE_ID and a description for this space\n",
    "# You can find the ID in the URL of the genie room /genie/rooms/<GENIE_SPACE_ID>\n",
    "# Example description: This Genie agent can answer questions based on a database containing tables related to enterprise software sales, including accounts, opportunities, opportunity history, fiscal periods, quotas, targets, teams, and users. Use Genie to fetch and analyze data from these tables by specifying the relevant columns and filters. Genie can execute SQL queries to provide precise data insights based on your questions.\n",
    "\n",
    "def create_genie_agent():\n",
    "    user_client = WorkspaceClient(credentials_strategy=ModelServingUserCredentials())\n",
    "\n",
    "    #TODO: Add the genie space id.\n",
    "    GENIE_SPACE_ID = \"01f0779845cc1c3894c6f962e9a79fdc\"\n",
    "    genie_agent_description = \"\"\"\n",
    "    This genie agent can answer questions on SQL transformations.\n",
    "        - Base all mappings on actual schema and comment info from the UC function calls.\n",
    "        Follow these instructions when writing SQL queries:\n",
    "            1. No made-up column names — if uncertain, choose the most likely mapping and explain in Assumptions.\n",
    "            2. Keep SQL ANSI-compliant and idiomatic for Databricks.\n",
    "            3. Use clear, readable formatting and aliasing.\n",
    "        \"\"\"\n",
    "\n",
    "    genie_agent = GenieAgent(\n",
    "        genie_space_id=GENIE_SPACE_ID,\n",
    "        genie_agent_name=\"DATA_MAPPING_ETL_AGENT\",\n",
    "        description=genie_agent_description,\n",
    "        client=user_client,\n",
    "    )\n",
    "    return(genie_agent)\n",
    "\n",
    "\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "#TODO: Add the genie space id.\n",
    "GENIE_SPACE_ID = \"01f0779845cc1c3894c6f962e9a79fdc\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "## Define tools for your agent, enabling it to retrieve data or take actions\n",
    "## beyond text generation\n",
    "## To create and see usage examples of more tools, see\n",
    "## https://docs.databricks.com/generative-ai/agent-framework/agent-tool.html\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# You can use UDFs in Unity Catalog as agent tools\n",
    "# def create_tools():\n",
    "#     tools = []\n",
    "#     uc_tool_names = [\"abhijeet_rao.ryder_demo.get_productivity_per_role\"] # TODO: Add Tools\n",
    "#     invokers_client = WorkspaceClient(credentials_strategy=ModelServingUserCredentials())\n",
    "#     invokers_func_client = DatabricksFunctionClient(client=invokers_client)\n",
    "#     uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names, client=invokers_func_client, filter_accessible_functions=True)\n",
    "#     tools.extend(uc_toolkit.tools)\n",
    "#     return tools\n",
    "\n",
    "\n",
    "#############################\n",
    "# Define the supervisor agent\n",
    "#############################\n",
    "\n",
    "# TODO update the max number of iterations between supervisor and worker nodes\n",
    "# before returning to the user\n",
    "MAX_ITERATIONS = 3\n",
    "\n",
    "genie_agent_description = \"\"\"\n",
    "    This genie agent can answer questions on SQL transformations.\n",
    "        - Base all mappings on actual schema and comment info from the UC function calls.\n",
    "        Follow these instructions when writing SQL queries:\n",
    "            1. No made-up column names — if uncertain, choose the most likely mapping and explain in Assumptions.\n",
    "            2. Keep SQL ANSI-compliant and idiomatic for Databricks.\n",
    "            3. Use clear, readable formatting and aliasing.\n",
    "        \"\"\"\n",
    "worker_descriptions = {\n",
    "    \"Genie\": genie_agent_description,\n",
    "}\n",
    "\n",
    "formatted_descriptions = \"\\n\".join(\n",
    "    f\"- {name}: {desc}\" for name, desc in worker_descriptions.items()\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a SQL transformations supervisor agent.\n",
    "\n",
    "Your primary purpose is to provide warehouse summaries with varying levels of detail based on the user's request. \n",
    "Because these summaries may require complex workflows, you have access to specialized worker agents that can be \n",
    "delegated specific tasks.\n",
    "\n",
    "These workers have access to the underlying data that the user’s questions may relate to. \n",
    "For every incoming request, you must decide whether to:\n",
    "    - Route tasks to one or more worker agents for execution, OR\n",
    "    - Respond directly to the user with the requested information.\n",
    "\n",
    "When delegating tasks:\n",
    "    1. Clearly define the expected output and scope for each worker.\n",
    "    2. Ensure that the results from workers align with the overall query and user intent.\n",
    "    3. Combine and summarize worker outputs into a coherent, user-friendly final response.\n",
    "\n",
    " \\n{formatted_descriptions}\n",
    "\n",
    "\"\"\"\n",
    "options = [\"FINISH\"] + list(worker_descriptions.keys())\n",
    "FINISH = {\"next_node\": \"FINISH\"}\n",
    "\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    count = state.get(\"iteration_count\", 0) + 1\n",
    "    if count > MAX_ITERATIONS:\n",
    "        return FINISH\n",
    "\n",
    "    class nextNode(BaseModel):\n",
    "        next_node: Literal[tuple(options)]\n",
    "\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    )\n",
    "    supervisor_chain = preprocessor | llm.with_structured_output(nextNode)\n",
    "    next_node = supervisor_chain.invoke(state).next_node\n",
    "\n",
    "    # if routed back to the same node, exit the loop\n",
    "    if state.get(\"next_node\") == next_node:\n",
    "        return FINISH\n",
    "    return {\n",
    "        \"iteration_count\": count,\n",
    "        \"next_node\": next_node\n",
    "    }\n",
    "\n",
    "#######################################\n",
    "# Define our multiagent graph structure\n",
    "#######################################\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": result[\"messages\"][-1].content,\n",
    "                \"name\": name,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def final_answer(state):\n",
    "    prompt = \"\"\"\n",
    "Using only the content in messages, respond to the previous user question using the answer provided by the other assistants.\n",
    "\n",
    "If you have the information needed to respond:\n",
    "    - Greet the user politely (e.g., Hi, Hello) and indicate that you plan to help with their problem.\n",
    "    - Provide a concise summary of the details from the workers’ outputs in two sentences or fewer.\n",
    "\n",
    "If the user requests information they do not have permissions for:\n",
    "    - The assistants will return a null or empty response.\n",
    "    - In that case, politely inform the user that the information could not be retrieved because they do not have access.\n",
    "    - Keep the response polite and concise.\n",
    "\n",
    "Important:\n",
    "    - Do not tell the user that *you* do not have access to their data.\n",
    "    - Workers have access to the data they are asking for; your role is to summarize or relay what they return.\n",
    "\"\"\"\n",
    "\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: state[\"messages\"] + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    final_answer_chain = preprocessor | llm\n",
    "    return {\"messages\": [final_answer_chain.invoke(state)]}\n",
    "\n",
    "\n",
    "class AgentState(ChatAgentState):\n",
    "    next_node: str\n",
    "    iteration_count: int\n",
    "\n",
    "\n",
    "def create_multi_agent_graph(genie_agent):\n",
    "    \"\"\"Builds and compiles the multi-agent LangGraph.\"\"\"\n",
    "\n",
    "    # Partially apply the agent_node function with the created genie_agent\n",
    "    genie_node = functools.partial(agent_node, agent=genie_agent, name=\"Genie\")\n",
    "\n",
    "    workflow = StateGraph(AgentState)\n",
    "    workflow.add_node(\"Genie\", genie_node)\n",
    "    workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "\n",
    "    workflow.add_node(\"final_answer\", final_answer)\n",
    "\n",
    "    workflow.set_entry_point(\"supervisor\")\n",
    "    \n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    for worker in worker_descriptions.keys():\n",
    "        workflow.add_edge(worker, \"supervisor\")\n",
    "\n",
    "    # Let the supervisor decide which next node to go\n",
    "    workflow.add_conditional_edges(\n",
    "        \"supervisor\",\n",
    "        lambda x: x[\"next_node\"],\n",
    "        {**{k: k for k in worker_descriptions.keys()}, \"FINISH\": \"final_answer\"},\n",
    "    )\n",
    "    workflow.add_edge(\"final_answer\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Custom constructor that does not require a pre-compiled agent.\n",
    "        The agent graph will be created dynamically in the predict methods.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def _predict_internal(self, messages: list[ChatAgentMessage]) -> CompiledStateGraph:\n",
    "        \"\"\"A helper method to create the agent and graph, and run the stream.\"\"\"\n",
    "        # 1. Create the agent with user credentials\n",
    "        genie_agent = create_genie_agent()\n",
    "\n",
    "        # 2. Create the graph using the newly created agent\n",
    "        multi_agent_graph = create_multi_agent_graph(genie_agent)\n",
    "\n",
    "        # 3. Prepare the request and stream the results\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "        return multi_agent_graph.stream(request, stream_mode=\"updates\")\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        \n",
    "        stream = self._predict_internal(messages)\n",
    "        output_messages = []\n",
    "        for event in stream:\n",
    "            for node_data in event.values():\n",
    "                output_messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "        return ChatAgentResponse(messages=output_messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        \n",
    "        stream = self._predict_internal(messages)\n",
    "        for event in stream:\n",
    "            for node_data in event.values():\n",
    "                # CHANGE THIS LINE:\n",
    "                # Use .get(\"messages\", []) to safely handle nodes that don't return messages.\n",
    "                yield from (\n",
    "                    ChatAgentChunk(**{\"delta\": msg}) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "\n",
    "\n",
    "# Create the agent object, and specify it as the agent object to use when\n",
    "# loading the agent back for inference via mlflow.models.set_model()\n",
    "AGENT = LangGraphChatAgent()\n",
    "mlflow.models.set_model(AGENT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5d4577d-81ab-46cc-8621-4a025c20f751",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output. Since this notebook called `mlflow.langchain.autolog()` you can view the trace for each step the agent takes.\n",
    "\n",
    "Replace this placeholder input with an appropriate domain-specific example for your agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "87ec4ede-ba0d-4f44-91ec-21ef30ffac93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e541f67c-2be7-4b08-9907-e25f3d83f79b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ChatAgentResponse(messages=[ChatAgentMessage(role='assistant', content='Please provide the chat history so I can assist you with the described information.', name='Genie', id='43dae9dc-13d0-4af9-9b72-69d5c66017e7', tool_calls=None, tool_call_id=None, attachments=None), ChatAgentMessage(role='assistant', content=\"# SQL Transformation for Silver Market Data\\n\\nI'll help you create a transformation query to populate your silver_market_data table from the bronze tables.\\n\\n```sql\\n-- SQL transformation to populate etl_assist_test.test_schema.silver_market_data\\nCREATE OR REPLACE TABLE etl_assist_test.test_schema.silver_market_data AS\\nSELECT \\n  p.date,\\n  s.ticker,\\n  s.name AS security_name,\\n  s.sector,\\n  s.industry,\\n  p.open_price,\\n  p.high_price,\\n  p.low_price,\\n  p.close_price,\\n  p.volume,\\n  p.adj_close\\nFROM etl_assist_test.test_schema.prices p\\nJOIN etl_assist_test.test_schema.securities s\\n  ON p.ticker = s.ticker;\\n```\\n\\nThis query joins the prices and securities tables on the ticker column, selecting relevant fields from both tables to create a comprehensive market data view in your silver layer.\", name=None, id='run--4aa8970b-435f-4aac-8a19-1e2da560418e-0', tool_calls=None, tool_call_id=None, attachments=None)], finish_reason=None, custom_outputs=None, usage=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-6b155a5c5309cb8c4755e601de2de043\", \"tr-2260b0987fc27566fb0f869582a335b5\"]",
      "text/plain": [
       "[Trace(trace_id=tr-6b155a5c5309cb8c4755e601de2de043), Trace(trace_id=tr-2260b0987fc27566fb0f869582a335b5)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \n",
    "                             \"content\": \"\"\"You are a SQL transformation expert working in Databricks with Unity Catalog.  \n",
    "Your task is to generate a transformation query to populate the destination table \n",
    "`etl_assist_test.test_schema.silver_market_data` from the bronze input tables \n",
    "`etl_assist_test.test_schema.prices` and `etl_assist_test.test_schema.securities\"\"\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "95765d5f-7dde-4aa1-ab69-a93c84e4e307",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta=ChatAgentMessage(role='assistant', content='This question is unrelated to the available database schema. The provided tables contain historical stock market data and securities information, not employee productivity or roles in a warehouse.', name='Genie', id='70e7744e-9d8e-4a2d-8af2-11996b565a88', tool_calls=None, tool_call_id=None, attachments=None) finish_reason=None custom_outputs=None usage=None -----------\n\ndelta=ChatAgentMessage(role='assistant', content=\"I don't have access to any warehouse employee productivity data in the available information. The database schema I have access to only contains historical stock market data and securities information, not employee roles or productivity metrics for a warehouse.\", name=None, id='run--526f7120-84a3-4257-8c0e-6b576e42d40e-0', tool_calls=None, tool_call_id=None, attachments=None) finish_reason=None custom_outputs=None usage=None -----------\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-7129640c6aa12993e84a94343570228b\", \"tr-b1edc8025a6b577dec13d85da26ac96e\"]",
      "text/plain": [
       "[Trace(trace_id=tr-7129640c6aa12993e84a94343570228b), Trace(trace_id=tr-b1edc8025a6b577dec13d85da26ac96e)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for event in AGENT.predict_stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Give me a breakdown of average productivity by employee role in the warehouse\"}]}\n",
    "):\n",
    "    print(event, \"-----------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66c2eb77-29b2-4949-b176-fd4abc1ccd12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Log the `agent` as an MLflow model\n",
    "Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "- **TODO**: If your Unity Catalog tool queries a [vector search index](https://docs.databricks.com/generative-ai/agent-framework/unstructured-retrieval-tools.html) or leverages [external functions](https://docs.databricks.com/generative-ai/agent-framework/external-connection-tools.html), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See [docs](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough) for more details.\n",
    "\n",
    "Log the agent as code from the `agent.py` file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e62f7ac5-1d0e-4e06-b7e8-395399503193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Endpoint Name: databricks-claude-3-7-sonnet\n"
     ]
    }
   ],
   "source": [
    "from agent import LLM_ENDPOINT_NAME\n",
    "print(f\"LLM Endpoint Name: {LLM_ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81eb715e-2a50-4b0d-a965-49c6b0419d3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 View Logged Model at: https://e2-demo-field-eng.cloud.databricks.com/ml/experiments/1985842046739892/models/m-aa6d366cccd64488afd9a311f3680e19?o=1444828305810485\n2025/08/12 18:51:03 INFO mlflow.pyfunc: Predicting on input example to validate output\n"
     ]
    }
   ],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from agent import LLM_ENDPOINT_NAME\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "from mlflow.models.auth_policy import AuthPolicy, SystemAuthPolicy, UserAuthPolicy\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "# TODO: Manually include underlying resources if needed. \n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "systemAuthPolicy = SystemAuthPolicy(resources=resources)\n",
    "\n",
    "# TODO: Manually include the required api scopes for this authorization.\n",
    "userAuthPolicy = UserAuthPolicy(api_scopes=[\"sql.statement-execution\", \"catalog.connections\", \"iam.current-user:read\", \"sql.warehouses\", \"dashboards.genie\", \"serving.serving-endpoints\", \"iam.access-control:read\", \"apps.apps\", \"mcp.functions\"])\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        pip_requirements=[\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "            f\"mlflow=={get_distribution('mlflow').version}\",\n",
    "            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "        ],\n",
    "        auth_policy=AuthPolicy(system_auth_policy=systemAuthPolicy, user_auth_policy=userAuthPolicy)\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e1f46ab-8da0-4e3c-b1b3-3550e97b4efc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with Agent Evaluation\n",
    "\n",
    "Use Mosaic AI Agent Evaluation to evalaute the agent's responses based on expected responses and other evaluation criteria. Use the evaluation criteria you specify to guide iterations, using MLflow to track the computed quality metrics.\n",
    "See Databricks documentation ([AWS]((https://docs.databricks.com/aws/generative-ai/agent-evaluation) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-evaluation/)).\n",
    "\n",
    "\n",
    "To evaluate your tool calls, add custom metrics. See Databricks documentation ([AWS](https://docs.databricks.com/mlflow3/genai/eval-monitor/custom-scorers) | [Azure](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/custom-scorers))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "36d959b4-9fe2-4898-a5dd-e2b5f5e2d3e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 18:51:31 INFO mlflow.models.evaluation.utils.trace: Auto tracing is temporarily enabled during the model evaluation for computing some metrics and debugging. To disable tracing, call `mlflow.autolog(disable=True)`.\n2025/08/12 18:51:31 INFO mlflow.genai.utils.data_validation: Testing model prediction with the first sample in the dataset.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e4484f9a08425591db2aafb9a5da5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [Elapsed: 00:00, Remaining: ?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <title>Evaluation output</title>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "        }\n",
       "\n",
       "        .header {\n",
       "            a.button {\n",
       "                padding: 4px 8px;\n",
       "                line-height: 20px;\n",
       "                box-shadow: none;\n",
       "                height: 20px;\n",
       "                display: inline-flex;\n",
       "                align-items: center;\n",
       "                justify-content: center;\n",
       "                vertical-align: middle;\n",
       "                background-color: rgb(34, 114, 180);\n",
       "                color: rgb(255, 255, 255);\n",
       "                text-decoration: none;\n",
       "                animation-duration: 0s;\n",
       "                transition: none 0s ease 0s;\n",
       "                position: relative;\n",
       "                white-space: nowrap;\n",
       "                text-align: center;\n",
       "                border: 1px solid rgb(192, 205, 216);\n",
       "                cursor: pointer;\n",
       "                user-select: none;\n",
       "                touch-action: manipulation;\n",
       "                border-radius: 4px;\n",
       "                gap: 6px;\n",
       "            }\n",
       "\n",
       "            a.button:hover {\n",
       "                background-color: rgb(14, 83, 139) !important;\n",
       "                border-color: transparent !important;\n",
       "                color: rgb(255, 255, 255) !important;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .warnings-section {\n",
       "            margin-top: 8px;\n",
       "\n",
       "            ul {\n",
       "                list-style-type: none;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .instructions-section {\n",
       "            margin-top: 16px;\n",
       "            font-size: 14px;\n",
       "\n",
       "            ul {\n",
       "                margin-top: 0;\n",
       "                margin-bottom: 0;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        code {\n",
       "            font-family: monospace;\n",
       "        }\n",
       "\n",
       "        .note {\n",
       "            color: #666;\n",
       "        }\n",
       "\n",
       "        a {\n",
       "            color: #2272B4;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "\n",
       "        a:hover {\n",
       "            color: #005580;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "    <div class=\"header\">\n",
       "        <a href=\"https://e2-demo-field-eng.cloud.databricks.com/ml/experiments/1985842046739892/evaluation-runs?selectedRunUuid=2d5109053ac64bffb997f9828d02e187/\" class=\"button\">\n",
       "            View evaluation results.\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1em\" height=\"1em\" fill=\"none\" viewBox=\"0 0 16 16\" aria-hidden=\"true\" focusable=\"false\" class=\"\">\n",
       "                <path fill=\"currentColor\" d=\"M10 1h5v5h-1.5V3.56L8.53 8.53 7.47 7.47l4.97-4.97H10z\"></path>\n",
       "                <path fill=\"currentColor\" d=\"M1 2.75A.75.75 0 0 1 1.75 2H8v1.5H2.5v10h10V8H14v6.25a.75.75 0 0 1-.75.75H1.75a.75.75 0 0 1-.75-.75z\"></path>\n",
       "            </svg>\n",
       "        </a>\n",
       "    </div>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-4c7aa80cfdde711bb1ccf431644bfb9d\"",
      "text/plain": [
       "Trace(trace_id=tr-4c7aa80cfdde711bb1ccf431644bfb9d)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, Safety\n",
    "\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"You are an assistant with access to warehouse employee productivity metrics stored in Unity Catalog. What is the average ProductivityScore of employees?\"}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda messages: AGENT.predict({\"messages\": messages}),\n",
    "    scorers=[RelevanceToQuery(), Safety()],\n",
    ")\n",
    "\n",
    "# Results will be in eval_results or visualized in MLflow UI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6368ebe6-de2d-4d05-a103-4fcfbc48c522",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Perform pre-deployment validation of the agent\n",
    "Before registering and deploying the agent, we perform pre-deployment checks via the [mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) API. See [documentation](https://docs.databricks.com/machine-learning/model-serving/model-serving-debug.html#validate-inputs) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "014e5269-8e2c-4659-8483-db474972ba77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 18:52:06 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n2025/08/12 18:52:09 INFO mlflow.utils.virtualenv: Creating a new environment in /tmp/virtualenv_envs/mlflow-fee2d303a0b1fcfbd87af6598d535999f80d04ab with python version 3.10.12 using uv\nUsing CPython 3.10.12 interpreter at: \u001B[36m/usr/bin/python3.10\u001B[39m\nCreating virtual environment at: \u001B[36m/tmp/virtualenv_envs/mlflow-fee2d303a0b1fcfbd87af6598d535999f80d04ab\u001B[39m\nActivate with: \u001B[32msource /tmp/virtualenv_envs/mlflow-fee2d303a0b1fcfbd87af6598d535999f80d04ab/bin/activate\u001B[39m\n2025/08/12 18:52:10 INFO mlflow.utils.virtualenv: Installing dependencies\n\u001B[2mUsing Python 3.10.12 environment at: /tmp/virtualenv_envs/mlflow-fee2d303a0b1fcfbd87af6598d535999f80d04ab\u001B[0m\n\u001B[2mResolved \u001B[1m3 packages\u001B[0m \u001B[2min 74ms\u001B[0m\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m setuptools \u001B[2m(1.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pip \u001B[2m(2.0MiB)\u001B[0m\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m setuptools\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m pip\n\u001B[2mPrepared \u001B[1m3 packages\u001B[0m \u001B[2min 266ms\u001B[0m\u001B[0m\n\u001B[2mInstalled \u001B[1m3 packages\u001B[0m \u001B[2min 47ms\u001B[0m\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpip\u001B[0m\u001B[2m==22.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msetuptools\u001B[0m\u001B[2m==80.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwheel\u001B[0m\u001B[2m==0.38.4\u001B[0m\n\u001B[2mUsing Python 3.10.12 environment at: /tmp/virtualenv_envs/mlflow-fee2d303a0b1fcfbd87af6598d535999f80d04ab\u001B[0m\n\u001B[2mResolved \u001B[1m126 packages\u001B[0m \u001B[2min 1.34s\u001B[0m\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m zstandard \u001B[2m(5.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m langchain-community \u001B[2m(2.4MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m grpcio \u001B[2m(5.9MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m matplotlib \u001B[2m(8.3MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-tracing \u001B[2m(1.0MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m tiktoken \u001B[2m(1.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m sqlalchemy \u001B[2m(3.1MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m scipy \u001B[2m(35.9MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-skinny \u001B[2m(1.9MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pillow \u001B[2m(6.3MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pydantic-core \u001B[2m(1.9MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m fonttools \u001B[2m(4.6MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m kiwisolver \u001B[2m(1.6MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pyarrow \u001B[2m(40.8MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m pandas \u001B[2m(11.8MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m numpy \u001B[2m(17.4MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m aiohttp \u001B[2m(1.6MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow \u001B[2m(24.6MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m scikit-learn \u001B[2m(9.2MiB)\u001B[0m\n\u001B[36m\u001B[1mDownloading\u001B[0m\u001B[39m databricks-connect \u001B[2m(2.3MiB)\u001B[0m\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m tiktoken\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m kiwisolver\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m aiohttp\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-tracing\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m pydantic-core\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m databricks-connect\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m sqlalchemy\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow-skinny\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m zstandard\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m fonttools\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m grpcio\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m pillow\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m matplotlib\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m langchain-community\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m scikit-learn\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m numpy\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m mlflow\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m pandas\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m scipy\n \u001B[32m\u001B[1mDownloading\u001B[0m\u001B[39m pyarrow\n\u001B[2mPrepared \u001B[1m125 packages\u001B[0m \u001B[2min 7.23s\u001B[0m\u001B[0m\n\u001B[1m\u001B[33mwarning\u001B[39m\u001B[0m\u001B[1m:\u001B[0m \u001B[1mThe module `\u001B[32mdatabricks\u001B[39m` is provided by more than one package, which causes an install race condition and can result in a broken module. Consider removing your dependency on either `\u001B[36mdatabricks-vectorsearch\u001B[39m` (v\u001B[36m0.57\u001B[39m) or `\u001B[36mdatabricks-sdk\u001B[39m` (v\u001B[36m0.62.0\u001B[39m).\u001B[0m\n\u001B[1m\u001B[33mwarning\u001B[39m\u001B[0m\u001B[1m:\u001B[0m \u001B[1mThe module `\u001B[32mdatabricks\u001B[39m` is provided by more than one package, which causes an install race condition and can result in a broken module. Consider removing your dependency on either `\u001B[36mdatabricks-sdk\u001B[39m` (v\u001B[36m0.62.0\u001B[39m) or `\u001B[36mdatabricks-connect\u001B[39m` (v\u001B[36m16.1.6\u001B[39m).\u001B[0m\n\u001B[1m\u001B[33mwarning\u001B[39m\u001B[0m\u001B[1m:\u001B[0m \u001B[1mThe module `\u001B[32mmlflow\u001B[39m` is provided by more than one package, which causes an install race condition and can result in a broken module. Consider removing your dependency on either `\u001B[36mmlflow-tracing\u001B[39m` (v\u001B[36m3.2.0\u001B[39m) or `\u001B[36mmlflow-skinny\u001B[39m` (v\u001B[36m3.2.0\u001B[39m).\u001B[0m\n\u001B[1m\u001B[33mwarning\u001B[39m\u001B[0m\u001B[1m:\u001B[0m \u001B[1mThe module `\u001B[32mmlflow\u001B[39m` is provided by more than one package, which causes an install race condition and can result in a broken module. Consider removing your dependency on either `\u001B[36mmlflow-skinny\u001B[39m` (v\u001B[36m3.2.0\u001B[39m) or `\u001B[36mmlflow\u001B[39m` (v\u001B[36m3.2.0\u001B[39m).\u001B[0m\n\u001B[2mInstalled \u001B[1m125 packages\u001B[0m \u001B[2min 752ms\u001B[0m\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiohappyeyeballs\u001B[0m\u001B[2m==2.6.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiohttp\u001B[0m\u001B[2m==3.12.15\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiohttp-retry\u001B[0m\u001B[2m==2.9.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1maiosignal\u001B[0m\u001B[2m==1.4.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1malembic\u001B[0m\u001B[2m==1.16.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mannotated-types\u001B[0m\u001B[2m==0.7.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1manyio\u001B[0m\u001B[2m==4.10.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1masync-timeout\u001B[0m\u001B[2m==4.0.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mattrs\u001B[0m\u001B[2m==25.3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mblinker\u001B[0m\u001B[2m==1.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcachetools\u001B[0m\u001B[2m==5.5.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcertifi\u001B[0m\u001B[2m==2025.8.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcharset-normalizer\u001B[0m\u001B[2m==3.4.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mclick\u001B[0m\u001B[2m==8.2.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcloudpickle\u001B[0m\u001B[2m==3.1.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcontourpy\u001B[0m\u001B[2m==1.3.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mcycler\u001B[0m\u001B[2m==0.12.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-ai-bridge\u001B[0m\u001B[2m==0.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-connect\u001B[0m\u001B[2m==16.1.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-langchain\u001B[0m\u001B[2m==0.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-sdk\u001B[0m\u001B[2m==0.62.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdatabricks-vectorsearch\u001B[0m\u001B[2m==0.57\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdataclasses-json\u001B[0m\u001B[2m==0.6.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdeprecation\u001B[0m\u001B[2m==2.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mdocker\u001B[0m\u001B[2m==7.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mexceptiongroup\u001B[0m\u001B[2m==1.3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfastapi\u001B[0m\u001B[2m==0.116.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mflask\u001B[0m\u001B[2m==3.1.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfonttools\u001B[0m\u001B[2m==4.59.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mfrozenlist\u001B[0m\u001B[2m==1.7.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgitdb\u001B[0m\u001B[2m==4.0.12\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgitpython\u001B[0m\u001B[2m==3.1.45\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgoogle-auth\u001B[0m\u001B[2m==2.40.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgoogleapis-common-protos\u001B[0m\u001B[2m==1.70.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphene\u001B[0m\u001B[2m==3.4.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphql-core\u001B[0m\u001B[2m==3.2.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgraphql-relay\u001B[0m\u001B[2m==3.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgreenlet\u001B[0m\u001B[2m==3.2.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgrpcio\u001B[0m\u001B[2m==1.74.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgrpcio-status\u001B[0m\u001B[2m==1.71.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mgunicorn\u001B[0m\u001B[2m==23.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mh11\u001B[0m\u001B[2m==0.16.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpcore\u001B[0m\u001B[2m==1.0.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpx\u001B[0m\u001B[2m==0.28.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mhttpx-sse\u001B[0m\u001B[2m==0.4.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1midna\u001B[0m\u001B[2m==3.10\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mimportlib-metadata\u001B[0m\u001B[2m==8.7.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mitsdangerous\u001B[0m\u001B[2m==2.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjinja2\u001B[0m\u001B[2m==3.1.6\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjoblib\u001B[0m\u001B[2m==1.5.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonpatch\u001B[0m\u001B[2m==1.33\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mjsonpointer\u001B[0m\u001B[2m==3.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mkiwisolver\u001B[0m\u001B[2m==1.4.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain\u001B[0m\u001B[2m==0.3.27\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain-community\u001B[0m\u001B[2m==0.3.27\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain-core\u001B[0m\u001B[2m==0.3.74\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangchain-text-splitters\u001B[0m\u001B[2m==0.3.9\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph\u001B[0m\u001B[2m==0.3.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph-checkpoint\u001B[0m\u001B[2m==2.1.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph-prebuilt\u001B[0m\u001B[2m==0.1.8\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlanggraph-sdk\u001B[0m\u001B[2m==0.1.74\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mlangsmith\u001B[0m\u001B[2m==0.4.13\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmako\u001B[0m\u001B[2m==1.3.10\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmarkupsafe\u001B[0m\u001B[2m==3.0.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmarshmallow\u001B[0m\u001B[2m==3.26.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmatplotlib\u001B[0m\u001B[2m==3.10.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow\u001B[0m\u001B[2m==3.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow-skinny\u001B[0m\u001B[2m==3.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmlflow-tracing\u001B[0m\u001B[2m==3.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmultidict\u001B[0m\u001B[2m==6.6.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mmypy-extensions\u001B[0m\u001B[2m==1.1.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnest-asyncio\u001B[0m\u001B[2m==1.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mnumpy\u001B[0m\u001B[2m==1.26.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-api\u001B[0m\u001B[2m==1.36.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-sdk\u001B[0m\u001B[2m==1.36.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mopentelemetry-semantic-conventions\u001B[0m\u001B[2m==0.57b0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1morjson\u001B[0m\u001B[2m==3.11.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mormsgpack\u001B[0m\u001B[2m==1.10.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpackaging\u001B[0m\u001B[2m==25.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpandas\u001B[0m\u001B[2m==2.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpillow\u001B[0m\u001B[2m==11.3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpropcache\u001B[0m\u001B[2m==0.3.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mprotobuf\u001B[0m\u001B[2m==5.29.5\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpy4j\u001B[0m\u001B[2m==0.10.9.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyarrow\u001B[0m\u001B[2m==21.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyasn1\u001B[0m\u001B[2m==0.6.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyasn1-modules\u001B[0m\u001B[2m==0.4.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic\u001B[0m\u001B[2m==2.11.7\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic-core\u001B[0m\u001B[2m==2.33.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpydantic-settings\u001B[0m\u001B[2m==2.10.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyparsing\u001B[0m\u001B[2m==3.2.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpython-dateutil\u001B[0m\u001B[2m==2.9.0.post0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpython-dotenv\u001B[0m\u001B[2m==1.1.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpytz\u001B[0m\u001B[2m==2025.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mpyyaml\u001B[0m\u001B[2m==6.0.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mregex\u001B[0m\u001B[2m==2025.7.34\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrequests\u001B[0m\u001B[2m==2.32.4\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrequests-toolbelt\u001B[0m\u001B[2m==1.0.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mrsa\u001B[0m\u001B[2m==4.9.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mscikit-learn\u001B[0m\u001B[2m==1.7.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mscipy\u001B[0m\u001B[2m==1.15.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msix\u001B[0m\u001B[2m==1.17.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msmmap\u001B[0m\u001B[2m==5.0.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msniffio\u001B[0m\u001B[2m==1.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msqlalchemy\u001B[0m\u001B[2m==2.0.43\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1msqlparse\u001B[0m\u001B[2m==0.5.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mstarlette\u001B[0m\u001B[2m==0.47.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtabulate\u001B[0m\u001B[2m==0.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtenacity\u001B[0m\u001B[2m==9.1.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mthreadpoolctl\u001B[0m\u001B[2m==3.6.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtiktoken\u001B[0m\u001B[2m==0.11.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtomli\u001B[0m\u001B[2m==2.2.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtyping-extensions\u001B[0m\u001B[2m==4.14.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtyping-inspect\u001B[0m\u001B[2m==0.9.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtyping-inspection\u001B[0m\u001B[2m==0.4.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mtzdata\u001B[0m\u001B[2m==2025.2\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1munitycatalog-ai\u001B[0m\u001B[2m==0.3.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1munitycatalog-client\u001B[0m\u001B[2m==0.3.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1munitycatalog-langchain\u001B[0m\u001B[2m==0.2.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1murllib3\u001B[0m\u001B[2m==2.5.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1muvicorn\u001B[0m\u001B[2m==0.35.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mwerkzeug\u001B[0m\u001B[2m==3.1.3\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1myarl\u001B[0m\u001B[2m==1.20.1\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mzipp\u001B[0m\u001B[2m==3.23.0\u001B[0m\n \u001B[32m+\u001B[39m \u001B[1mzstandard\u001B[0m\u001B[2m==0.23.0\u001B[0m\n2025/08/12 18:52:20 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs/mlflow-fee2d303a0b1fcfbd87af6598d535999f80d04ab/bin/activate && python -c \"\"']'\n2025/08/12 18:52:20 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs/mlflow-fee2d303a0b1fcfbd87af6598d535999f80d04ab/bin/activate && python /local_disk0/.ephemeral_nfs/envs/pythonEnv-bf54fcca-fd96-4a86-a804-f7504611dc2b/lib/python3.10/site-packages/mlflow/pyfunc/_mlflow_pyfunc_backend_predict.py --model-uri file:///local_disk0/user_tmp_data/spark-bf54fcca-fd96-4a86-a804-f7/tmpu9xi7u78/agent --content-type json --input-path /local_disk0/user_tmp_data/spark-bf54fcca-fd96-4a86-a804-f7/tmp23xljpjj/input.json']'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"messages\": [{\"role\": \"assistant\", \"content\": \"Hello! Please provide the chat history, and I'll assist you with the described information.\", \"name\": \"Genie\", \"id\": \"7f0fa540-7874-493e-9462-01701b646167\"}, {\"role\": \"assistant\", \"content\": \"I notice you've shared instructions that appear to be meant for me rather than a question you want answered. These instructions seem to be describing how I should respond to user questions using information from other assistants.\\n\\nIf you have a specific question you'd like help with, please feel free to ask, and I'll do my best to assist you directly. I don't need to relay information from other assistants to help with your questions.\", \"id\": \"run--296b1093-7f61-4d83-bdf6-95ec1f905553-0\"}]}"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 18:52:44 INFO mlflow.tracing.export.async_export_queue: Flushing the async trace logging queue before program exit. This may take a while...\n"
     ]
    }
   ],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data={\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]},\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cc854e2-c345-44e2-85cf-ae2be14495b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "\n",
    "Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aaf9eb9-933c-460e-a452-d5bfbb07be5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'etl_assist_test.test_schema.etl_assist_agent'.\n\uD83D\uDD17 Created version '1' of model 'etl_assist_test.test_schema.etl_assist_agent': https://e2-demo-field-eng.cloud.databricks.com/explore/data/models/etl_assist_test/test_schema/etl_assist_agent/version/1?o=1444828305810485\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"etl_assist_test\"\n",
    "schema = \"test_schema\"\n",
    "model_name = \"etl_assist_agent\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b6a4540-fdf0-4116-87bf-7c136751b745",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5da4b64c-2ede-483e-8ad3-1a0e7c45d0dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n    Deployment of etl_assist_test.test_schema.etl_assist_agent version 1 initiated.  This can take up to 15 minutes and the Review App & Query Endpoint will not work until this deployment finishes.\n\n    View status: https://e2-demo-field-eng.cloud.databricks.com/ml/endpoints/agents_etl_assist_test-test_schema-etl_assist_agent\n    Review App: https://e2-demo-field-eng.cloud.databricks.com/ml/review-v2/2b6655e0c39f49f7920d65afd1d01d6e/chat\n    Monitor: https://e2-demo-field-eng.cloud.databricks.com/ml/experiments/1985842046739892?compareRunsMode=TRACES\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Deployment(model_name='etl_assist_test.test_schema.etl_assist_agent', model_version='1', endpoint_name='agents_etl_assist_test-test_schema-etl_assist_agent', served_entity_name='etl_assist_test-test_schema-etl_assist_agent_1', query_endpoint='https://e2-demo-field-eng.cloud.databricks.com/serving-endpoints/agents_etl_assist_test-test_schema-etl_assist_agent/served-models/etl_assist_test-test_schema-etl_assist_agent_1/invocations', endpoint_url='https://e2-demo-field-eng.cloud.databricks.com/ml/endpoints/agents_etl_assist_test-test_schema-etl_assist_agent', review_app_url='https://e2-demo-field-eng.cloud.databricks.com/ml/review-v2/2b6655e0c39f49f7920d65afd1d01d6e/chat')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from databricks import agents\n",
    "agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version, tags = {\"endpointSource\": \"docs\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db6cd9d1-96db-4017-ac56-0065437d3501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See [docs](https://docs.databricks.com/generative-ai/deploy-agent.html) for details"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ua-genie-agents-etl-assist",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}